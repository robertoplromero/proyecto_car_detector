{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0310549f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∏ Procesando 1615 im√°genes...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84a42be3a3148068ba1e087cec4bd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1615 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ¬°Listo! Se generaron 1647 recortes de autos en '../../data/processed/car_crops_test'\n"
     ]
    }
   ],
   "source": [
    "# T√çTULO: Inferencia y Generaci√≥n de Recortes (ROI)\n",
    "# OBJETIVO: Validar el modelo de autos y generar los inputs para el detector de placas.\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- CONFIGURACI√ìN ---\n",
    "# Ruta relativa a tu mejor modelo (ajusta la fecha si es necesario)\n",
    "MODEL_PATH = '../../production_weights/01_autos_best.pt' \n",
    "# Si a√∫n no lo moviste a production, usa la ruta de models/vehicle_detector/...\n",
    "\n",
    "# Im√°genes de prueba (pueden ser las del test set o nuevas descargadas de internet)\n",
    "TEST_IMAGES_DIR = '../../datasets/01_autos/test/images'\n",
    "OUTPUT_DIR = '../../data/processed/car_crops_test'\n",
    "\n",
    "# Cargar Modelo\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# Crear carpeta de salida\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def extract_crops(source_dir, output_dir):\n",
    "    image_paths = glob.glob(os.path.join(source_dir, '*.jpg'))\n",
    "    print(f\"üì∏ Procesando {len(image_paths)} im√°genes...\")\n",
    "    \n",
    "    count = 0\n",
    "    for img_path in tqdm(image_paths):\n",
    "        # Inferencia\n",
    "        # conf=0.5: Solo autos con alta confianza\n",
    "        results = model.predict(img_path, conf=0.5, verbose=False)\n",
    "        \n",
    "        original_img = cv2.imread(img_path)\n",
    "        if original_img is None: continue\n",
    "        \n",
    "        for r in results:\n",
    "            boxes = r.boxes\n",
    "            for i, box in enumerate(boxes):\n",
    "                # Coordenadas\n",
    "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "                \n",
    "                # RECORTE (La magia del pipeline)\n",
    "                # Validar l√≠mites para no romper cv2\n",
    "                h, w, _ = original_img.shape\n",
    "                x1, y1 = max(0, x1), max(0, y1)\n",
    "                x2, y2 = min(w, x2), min(h, y2)\n",
    "                \n",
    "                crop = original_img[y1:y2, x1:x2]\n",
    "                \n",
    "                # Guardar recorte si tiene un tama√±o decente\n",
    "                if crop.size > 0 and crop.shape[0] > 10 and crop.shape[1] > 10:\n",
    "                    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "                    save_name = f\"{base_name}_crop_{i}.jpg\"\n",
    "                    cv2.imwrite(os.path.join(output_dir, save_name), crop)\n",
    "                    count += 1\n",
    "\n",
    "    print(f\"‚úÖ ¬°Listo! Se generaron {count} recortes de autos en '{output_dir}'\")\n",
    "\n",
    "# Ejecutar\n",
    "extract_crops(TEST_IMAGES_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89898efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "‚ö° Velocidad de Inferencia: 50.34 FPS\n",
      "‚è±Ô∏è Latencia por imagen: 19.86 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Mide velocidad pura\n",
    "start = time.time()\n",
    "results = model.predict(TEST_IMAGES_DIR, device=0, verbose=False)\n",
    "end = time.time()\n",
    "\n",
    "total_time = end - start\n",
    "fps = len(results) / total_time\n",
    "\n",
    "print(f\"‚ö° Velocidad de Inferencia: {fps:.2f} FPS\")\n",
    "print(f\"‚è±Ô∏è Latencia por imagen: {(total_time/len(results))*1000:.2f} ms\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
